<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>给女朋友写的一个简书爬虫 | 咸鱼老弟</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/7.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">给女朋友写的一个简书爬虫</h1><a id="logo" href="/.">咸鱼老弟</a><p class="description">【博客园-咸鱼老弟】</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/resource/"><i class="fa fa-university"> 资源</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">给女朋友写的一个简书爬虫</h1><div class="post-meta">Nov 29, 2017<span> | </span><span class="category"><a href="/categories/node/">node</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、前期分析："><span class="toc-number">1.</span> <span class="toc-text">一、前期分析：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、前期准备："><span class="toc-number">2.</span> <span class="toc-text">二、前期准备：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三、开始爬虫"><span class="toc-number">3.</span> <span class="toc-text">三、开始爬虫</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#注意点"><span class="toc-number">4.</span> <span class="toc-text">注意点:</span></a></li></ol></div></div><div class="post-content"><blockquote>
<p>背景：女票参加了一个简书的写作训练营，并担任某个小班的班长，每个周末需要统计每个学员上一周写了多少篇文章以及写了哪些文章等数据。为了讨女票开心，于是就答应给她写一个简书的爬虫，用于统计数据，毕竟咋是搞这行的，能用程序解决的就坚决就不去做那种重复的体力活。<br>下面，咋一起来进入这个爬虫的书写</p>
</blockquote>
<a id="more"></a>
<h2 id="一、前期分析："><a href="#一、前期分析：" class="headerlink" title="一、前期分析："></a>一、前期分析：</h2><p>  首先我们来分析一下我们要怎么爬，如图所示:<br>  <img src="/img/jianshu_1.png" alt=""></p>
<p>  <strong> 第一步：</strong></p>
<p>   我们需要进入到每个学员的用户中心，类似于这种链接： <a href="http://www.jianshu.com/u/eeb221fb7dac" target="_blank" rel="noopener">http://www.jianshu.com/u/eeb221fb7dac</a></p>
<p>   这个只能由女票帮我们收集好她们班每个学员的用户中心的链接。有了这种用户中心的链接后，我们第一步要爬的就是这个用户中心</p>
<p>  <strong> 第二步：</strong></p>
<p>  爬取用户中心，我们需要获取到某些数据。如：我们统计的是上一周数据，所以需要某个时间段内，文章详情的链接集合、 用户名。</p>
<p>  这些数据如何获取呢？如上图所示： 获取用户名，我们需要 <code>$(&#39;.nickname&#39;)</code> 这里的文本即可。获取某个时间段的文章详情链接，我们需要遍历 <code>$(&#39;.note-list li&#39;)</code>中的 <code>$(&#39;.time&#39;)</code> 和 <code>$(&#39;.titile&#39;)</code></p>
<p>  <strong> 第三步：</strong></p>
<p>  爬取第二步获取到的文章详情链接，爬取文章详情里面的内容，文章详情类似的链接为： <a href="http://www.jianshu.com/p/aeaa1f2a0196" target="_blank" rel="noopener">http://www.jianshu.com/p/aeaa1f2a0196</a></p>
<p>  在文章详情页中，获取我们需要的数据，如： 标题，字数，阅读数等等。 如下图所示</p>
<p>  <img src="/img/jianshu_2.png" alt=""></p>
<p>  <strong> 第四步：</strong></p>
<p>  将获取的数据生成excel表，这样女票才会更加的崇拜你，哇，斯国一。</p>
<h2 id="二、前期准备："><a href="#二、前期准备：" class="headerlink" title="二、前期准备："></a>二、前期准备：</h2><p>   经常上面的分析，下面我们来准备爬虫需要的工具：</p>
<ol>
<li><p><code>cheerio</code>: 让你可以像使用jquery一样操作爬取回来的页面</p>
</li>
<li><p><code>superagent-charset</code>: 解决爬回来的页面编码问题</p>
</li>
<li><p><code>superagent</code>: 用于发起请求</p>
</li>
<li><p><code>async</code>: 用于异步流程和并发控制</p>
</li>
<li><p><code>ejsexcel</code>: 用于生成excel表格</p>
</li>
<li><p><code>express</code>、 <code>node &gt;=6.0.0</code></p>
<p>这些模块具体用法，可以在这里查，<a href="https://www.npmjs.com" target="_blank" rel="noopener">https://www.npmjs.com</a> ，一些用法下面会说到</p>
</li>
</ol>
<h2 id="三、开始爬虫"><a href="#三、开始爬虫" class="headerlink" title="三、开始爬虫"></a>三、开始爬虫</h2><p>  1.我们将所有学员的简书用户中心链接放在配置文件 config.js中，并定义了生成的excel表存放路径:</p>
  <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> path = <span class="built_in">require</span>(<span class="string">'path'</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">module</span>.exports = &#123;</span><br><span class="line">  excelFile: &#123;</span><br><span class="line">    path: path.join(__dirname, <span class="string">'public/excel/'</span>)</span><br><span class="line">  &#125;,  </span><br><span class="line">  data: [</span><br><span class="line">    &#123;<span class="attr">name</span>:<span class="string">"糕小糕"</span>,<span class="attr">url</span>:<span class="string">"http://www.jianshu.com/u/eeb221fb7dac"</span>&#125;,</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  由于要保护别人的信息，所以你可以去简书随便找其他人的用户中心，造更多的数据</p>
<p>  2.我们先定义一些全局变量,如: 基础的链接，当前并发数，抓取错误的链接集合<br>   <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> _baseUrl = <span class="string">"http://www.jianshu.com"</span>,</span><br><span class="line">    _currentCount = <span class="number">0</span>,</span><br><span class="line">    _errorUrls = [];</span><br></pre></td></tr></table></figure></p>
<p>  3.封装一些函数:<br>  <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 封装 superagent 函数</span></span><br><span class="line"><span class="keyword">const</span> fetchUrl = <span class="function">(<span class="params">url,callback</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">let</span> fetchStart = <span class="keyword">new</span> <span class="built_in">Date</span>().getTime();</span><br><span class="line">  superagent</span><br><span class="line">    .get(url)</span><br><span class="line">    .charset(<span class="string">'utf-8'</span>)</span><br><span class="line">    .end(<span class="function">(<span class="params">err, ssres</span>) =&gt;</span> &#123;   </span><br><span class="line">      <span class="keyword">if</span>(err) &#123;</span><br><span class="line">        _errorUrls.push(url);</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">'抓取【'</span>+ url +<span class="string">'】出错'</span>); </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;       </span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">let</span> spendTime = <span class="keyword">new</span> <span class="built_in">Date</span>().getTime() - fetchStart;</span><br><span class="line">      <span class="built_in">console</span>.log(<span class="string">'抓取:'</span>+ url +<span class="string">'成功,耗时：'</span>+ spendTime +<span class="string">'毫秒,现在并发数为:'</span>+ _currentCount );</span><br><span class="line">      _currentCount--;</span><br><span class="line">      callback(ssres.text);</span><br><span class="line">  &#125;);       </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// 数组去重</span></span><br><span class="line"><span class="keyword">const</span> removeSame = <span class="function">(<span class="params">arr</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">const</span> newArr = [];</span><br><span class="line">  <span class="keyword">const</span> obj = &#123;&#125;;</span><br><span class="line">  arr.forEach(<span class="function">(<span class="params">item</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span>(!obj[item.title]) &#123;</span><br><span class="line">      newArr.push(item);</span><br><span class="line">      obj[item.title] = item.title;</span><br><span class="line">    &#125; </span><br><span class="line">  &#125;);</span><br><span class="line">  <span class="keyword">return</span> newArr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>  4.开始爬取用户中心,获取某个时间段的文章详情链接</p>
  <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 爬取用户中心，获取某个时间段文章详情链接</span></span><br><span class="line"><span class="keyword">const</span> crawlUserCenter = <span class="function">(<span class="params">res,startTime,endTime</span>) =&gt;</span> &#123;  <span class="comment">//startTime,endTime来自于用户的ajax请求时间</span></span><br><span class="line">  <span class="keyword">const</span> centerUrlArr = config.data;</span><br><span class="line">  <span class="keyword">async</span>.mapLimit(centerUrlArr, <span class="number">5</span>, (elem, callback) =&gt; &#123; </span><br><span class="line">    _currentCount++;</span><br><span class="line">    fetchUrl(elem.url, (html) =&gt; &#123;</span><br><span class="line">      <span class="keyword">const</span> $ = cheerio.load(html);</span><br><span class="line">      <span class="keyword">const</span> detailUrlArr = getDetailUrlCollections($,startTime,endTime); </span><br><span class="line">      callback(<span class="literal">null</span>,detailUrlArr);  <span class="comment">//callback是必须的</span></span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">  &#125;, (err, detailUrlArr) =&gt; &#123; <span class="comment">// 并发结束后的结果 ，需要由 [[abc,def],[hij,xxx]] =&gt; [abc,def,hij,xxx]</span></span><br><span class="line">    _currentCount = <span class="number">0</span>;</span><br><span class="line">    crawArticleDetail(detailUrlArr,res);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;);   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  在这里，用户中心的链接来自于 confg文件，我们使用 <code>async.mapLimit</code>来对我们的抓取做了一个并发控制，并发数最大为5。</p>
<p>  <code>async.mapLimit</code>用法为: <code>mapLimit(arr, limit, iterator, callback)</code>;<br>  <code>arr</code>: 数组<br>  <code>limit</code>: 并发数<br>  <code>iterator</code>: 迭代器(处理函数), 这里指爬取一次用户中心，它里面 <strong> callback必须执行 </strong>，将本次执行结果存储起来。<br>  <code>callback</code>: 执行完成之后的回调。 所有的用户中心抓取完，抓取到的总结果返回这个回调里面。</p>
<p>  从用户中心获取某个时间段的文章详情集合:<br>  <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取某个时间段文章链接集合</span></span><br><span class="line"><span class="keyword">const</span> getDetailUrlCollections = <span class="function">(<span class="params">$,startTime,endTime</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">let</span> articleList = $(<span class="string">'#list-container .note-list li'</span>),</span><br><span class="line">      detailUrlCollections = [];</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">let</span> i = <span class="number">0</span>,len = articleList.length; i &lt; len; i++) &#123;</span><br><span class="line">    <span class="keyword">let</span> crateAt = articleList.eq(i).find(<span class="string">'.author .time'</span>).attr(<span class="string">'data-shared-at'</span>);</span><br><span class="line">    <span class="keyword">let</span> createTime = <span class="keyword">new</span> <span class="built_in">Date</span>(crateAt).getTime();</span><br><span class="line">    <span class="keyword">if</span>(createTime &gt;= startTime &amp;&amp; createTime &lt;= endTime) &#123;</span><br><span class="line">      <span class="keyword">let</span> articleUrl = articleList.eq(i).find(<span class="string">'.title'</span>).attr(<span class="string">'href'</span>);</span><br><span class="line">      <span class="keyword">let</span> url = _baseUrl + articleUrl;</span><br><span class="line">      detailUrlCollections.push(url);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; </span><br><span class="line">  <span class="keyword">return</span> detailUrlCollections;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>  5.从第4步中，我们获取到了所有的文章详情链接，所以，下面我们来爬取文章详情里面的内容，做法跟第4步差不多</p>
  <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 爬取文章详情</span></span><br><span class="line"><span class="keyword">const</span> crawArticleDetail = <span class="function">(<span class="params">detailUrls,res</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">const</span> detailUrlArr = spreadDetailUrl(detailUrls);</span><br><span class="line">  <span class="keyword">async</span>.mapLimit(detailUrlArr, <span class="number">5</span>, (url, callback) =&gt; &#123; </span><br><span class="line">    _currentCount ++;</span><br><span class="line">    fetchUrl(url, (html) =&gt; &#123;</span><br><span class="line">      <span class="keyword">const</span> $ = cheerio.load(html,&#123;<span class="attr">decodeEntities</span>: <span class="literal">false</span>&#125;);</span><br><span class="line">      <span class="keyword">const</span>  data = &#123;</span><br><span class="line">        title: $(<span class="string">'.article .title'</span>).html(),</span><br><span class="line">        wordage: $(<span class="string">'.article .wordage'</span>).html(),</span><br><span class="line">        publishTime: $(<span class="string">'.article .publish-time'</span>).html(),</span><br><span class="line">        author: $(<span class="string">'.author .name a'</span>).html()</span><br><span class="line">      &#125;; </span><br><span class="line">      callback(<span class="literal">null</span>,data);  </span><br><span class="line">    &#125;);</span><br><span class="line">   </span><br><span class="line">  &#125;, (err, resData) =&gt; &#123;</span><br><span class="line">    <span class="keyword">let</span> result = removeSame(resData);</span><br><span class="line">    <span class="keyword">const</span> sumUpData = sumUpResult(result);</span><br><span class="line">    res.json(&#123;</span><br><span class="line">      data: result,</span><br><span class="line">      sumUpData: sumUpData</span><br><span class="line">    &#125;);</span><br><span class="line">    createExcel(result,sumUpData);</span><br><span class="line">    <span class="built_in">console</span>.info(<span class="string">'抓取数据完毕，一共抓取了：'</span>+ result.length +<span class="string">'篇文章，其中，错误数为：'</span> + _errorUrls.length +<span class="string">'条'</span>);</span><br><span class="line">    <span class="keyword">if</span>(_errorUrls.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="built_in">console</span>.info(<span class="string">'错误的url为:'</span> + _errorUrls.join(<span class="string">','</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// [[abc,def],[hij,xxx]] =&gt; [abc,def,hij,xxx]</span></span><br><span class="line"><span class="keyword">const</span> spreadDetailUrl= <span class="function">(<span class="params">urls</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">const</span> urlCollections = [];</span><br><span class="line">  urls.forEach(<span class="function">(<span class="params">item</span>) =&gt;</span> &#123;</span><br><span class="line">    item.forEach(<span class="function">(<span class="params">url</span>) =&gt;</span> &#123;</span><br><span class="line">      urlCollections.push(url);</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;);   </span><br><span class="line">  <span class="keyword">return</span> urlCollections;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  从文章详情里，我们获取了标题，字数，发布时间，当然，你可以获取该页面你想要的信息，我这里不需要太多，这些就够了。这里获取到的数据是有重复的，所以要做数组去重处理</p>
<p>  6.至此，我们需要爬取的数据都获取到了，最后一步，我们将其生成excel表格</p>
<p>  用node生成excel表，找了一圈，发觉 <code>ejsexcel</code> 这个框架评价比较好。<a href="https://www.npmjs.com/package/ejsexcel" target="_blank" rel="noopener">点击查看</a>;</p>
<p>  它的使用方法为: 我们先需要有一个excel表模板，然后在改模板里面，可以使用ejs语法，来按照我们的意思生成表格<br>  <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 生成excel表</span></span><br><span class="line"><span class="keyword">const</span> createExcel = <span class="function">(<span class="params">dataArr,sumUpData</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">const</span> exlBuf = fs.readFileSync(config.excelFile.path + <span class="string">"/report.xlsx"</span>);</span><br><span class="line">  <span class="comment">//数据源</span></span><br><span class="line">  <span class="keyword">const</span> data = [ [&#123;<span class="string">"table_name"</span>:<span class="string">"7班简书统计表"</span>,<span class="string">"date"</span>: formatTime()&#125;], dataArr, sumUpData ];</span><br><span class="line">  <span class="comment">//用数据源(对象)data渲染Excel模板</span></span><br><span class="line">  ejsExcel.renderExcel(exlBuf, data)</span><br><span class="line">  .then(<span class="function"><span class="keyword">function</span>(<span class="params">exlBuf2</span>) </span>&#123;</span><br><span class="line">      fs.writeFileSync(config.excelFile.path + <span class="string">"/report2.xlsx"</span>, exlBuf2);</span><br><span class="line">      <span class="built_in">console</span>.log(<span class="string">"生成excel表成功"</span>);</span><br><span class="line">  &#125;).catch(<span class="function"><span class="keyword">function</span>(<span class="params">err</span>) </span>&#123;</span><br><span class="line">      <span class="built_in">console</span>.error(<span class="string">'生成excel表失败'</span>);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>  先读取我们的模板，然后再将我们的数据写入到模板中，生成新的excel表格<br>  <img src="/img/excel_temp.png" alt="excel模板"></p>
<p>  7.由于抓取的时间是不固定的，所以我们将整个抓取的过程弄成由前端ajax请求的形式，传递 startTime 和 endTime这两个数据，前端界面比较简单<br>  <img src="/img/jianshu_fed.png" alt="前端界面"></p>
<p>  生成的excel表格图:<br>  <img src="/img/jianshu_excel.png" alt="前端界面"></p>
<p>  抓取的过程如下:<br>  <img src="/img/spider.gif" alt=""></p>
<p>  至此，我们的简书爬虫完成了，比较简单。</p>
<h2 id="注意点"><a href="#注意点" class="headerlink" title="注意点:"></a>注意点:</h2><p>  由于只能抓取用户中心中的第一页数据，所以时间的选择上，最好选择上一周时间内。而且excel表格生成时，要把excel关了，不然会导致生成excel表不成功。</p>
<p>  代码已放在github中,欢迎使用(希望简书不会把我拉黑):  <a href="https://github.com/xianyulaodi/jianshu_spider" target="_blank" rel="noopener">前往github</a>.</p>
<p>  对了，这个爬虫的名字叫做： 大黄蜂</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="https://xianyulaodi.github.io/2017/11/29/给女朋友写的一个简书爬虫/" data-id="cjezvpkyy001qf8p6exhtbz3a" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACvklEQVR42u3aQW4jMQwEwPz/01lgzzt2NyklxqLmZCSOhzUBJLqpr6/4+v57Pb1++snTb5/e+XTf1+85cOHh4eGNSk/Kel3E63e+/vy8wrxmPDw8vNu8vOin0l8XlBSabEJ5zXh4eHifwDvbNOctNR4eHt7/xJs11smWkNeDh4eH91u8fLlvW+E8Wc3fcyVrwcPDw4t5+wHYz7/+0fkeHh4eXrwlbKLb2VGANv54Uy0eHh7eBd7rW7bRQN7U5g33bBeInigeHh7eIV670LdHB/L77jcSPDw8vHu8TegwQ+abUN6gR48VDw8P7yivGMavG/FZDLH6B+Dh4eEd4uVh6Oz4VL4lJKFt3e7j4eHhXeC1bXE+4pq1v+1RreH/Ew8PD2/N2xxyagf5SYs8C4Wj7wp4eHh4a15SRB4H3JvX51vRmzNleHh4eGtee20igzzYnT1oPDw8vJ/hvQ5n85FVO5rKl/g2OP7HAAwPDw/vMm8z4poV14YX9TcGPDw8vKO8fOzULt/5dnLquMBjVXh4eHgXeHkI27bLbTzRHqUaZi14eHh4l3n5oavNsYAWv0qm8fDw8I7yZgFrvkzvR2KrCw8PD+8QLz901Ya5+ee3QXDx6PHw8PCO8vLmtR1uzaKNzdZVzPfw8PDwFrx9MNoOq2aHt5JtKYqA8fDw8Na82cBpv2EkjyN/cHh4eHi/y5u1y6ci2nzpj7YuPDw8vAu8duw0Cy/aUtrRV1QnHh4e3iHed3nNNpV2G0jW9uhz8PDw8C7wNmOn2eAqacHbgwV5mIKHh4d3itcermqHWLPWua0h+q6Ah4eHd5Q3u32+Ds/+arWb4eHh4X0Arz0O1d6ljXGjxhoPDw/vA3h5oLDZQvLA4k3DjYeHh3eN14YRbZTQBsR5vPvmgeLh4eFd4J0agM3ig1lce4CEh4eHN+H9ARNr7gPkaWVkAAAAAElFTkSuQmCC" class="article-share-link">分享</a><div class="tags"><a href="/tags/爬虫/">爬虫</a></div><div class="post-nav"><a href="/2018/01/22/将中文转为拼音首字母/" class="pre">js提取中文拼音首字母</a><a href="/2017/09/24/nodejs学习小结/" class="next">nodejs学习小结</a></div><div id="container"></div><link rel="stylesheet" href="/css/default.css?v=0.0.0"><script src="/js/gitment.browser.js?v=0.0.0"></script><script>var gitment = new Gitment({
  owner: 'xianyulaodi',
  repo: 'myBlogCommentRepo',
  oauth: {
    client_id: 'bb8f1145bdd0717d9830',
    client_secret: 'b18dc8d3b04cea043cb47d083049276cd93e0503',
  },
})
gitment.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://xianyulaodi.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/js/">js</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/node/">node</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/vue/">vue</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/高阶函数/" style="font-size: 15px;">高阶函数</a> <a href="/tags/node/" style="font-size: 15px;">node</a> <a href="/tags/BigPipe/" style="font-size: 15px;">BigPipe</a> <a href="/tags/expess/" style="font-size: 15px;">expess</a> <a href="/tags/博客园迁移/" style="font-size: 15px;">博客园迁移</a> <a href="/tags/cookie/" style="font-size: 15px;">cookie</a> <a href="/tags/mongoose/" style="font-size: 15px;">mongoose</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/js/" style="font-size: 15px;">js</a> <a href="/tags/github/" style="font-size: 15px;">github</a> <a href="/tags/path/" style="font-size: 15px;">path</a> <a href="/tags/fs/" style="font-size: 15px;">fs</a> <a href="/tags/setTimeout/" style="font-size: 15px;">setTimeout</a> <a href="/tags/Eventloop/" style="font-size: 15px;">Eventloop</a> <a href="/tags/npm/" style="font-size: 15px;">npm</a> <a href="/tags/vue/" style="font-size: 15px;">vue</a> <a href="/tags/vuex/" style="font-size: 15px;">vuex</a> <a href="/tags/vue-router/" style="font-size: 15px;">vue-router</a> <a href="/tags/router/" style="font-size: 15px;">router</a> <a href="/tags/css/" style="font-size: 15px;">css</a> <a href="/tags/正则/" style="font-size: 15px;">正则</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/03/20/一次code review引发的思考/">一次code review引发的思考</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/02/25/如何写一个npm包/">如何写一个npm包</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/02/10/BigPipe小探/">BigPipe小探</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/22/将中文转为拼音首字母/">js提取中文拼音首字母</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/29/给女朋友写的一个简书爬虫/">给女朋友写的一个简书爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/24/nodejs学习小结/">nodejs学习小结</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/12/express图片上传/">express图片上传</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/19/浅析css中的cursor/">浅析css中的cursor</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/03/javascript高阶函数/">javascript高阶函数</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/18/手写一个router/">手写一个router</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-money"> 请博主喝咖啡</i><img src="/img/WeChatQR.png"/></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.cnblogs.com/xianyulaodi/" title="我的博客园" target="_blank">我的博客园</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">咸鱼老弟.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>